from pyspark.sql.functions import udf, array
from pyspark.sql.types import ArrayType, FloatType

# UDF para combinar colunas de recursos em um vetor
def combine_features(*cols):
    return [float(x) for x in cols]

# Registrando a UDF
combine_features_udf = udf(combine_features, ArrayType(FloatType()))

# Suponha que você tenha um DataFrame com múltiplas colunas de recursos
df = spark.createDataFrame(
    [(0, 1.0, 3.0, 7.0), (1, 2.0, 5.0, 8.0), (2, 4.0, 6.0, 9.0)],
    ["id", "feature1", "feature2", "feature3"]
)

# Usando a UDF para criar a coluna 'features'
df_combined = df.withColumn("features", combine_features_udf("feature1", "feature2", "feature3"))

df_combined.show(truncate=False)



# Usando a função array para combinar colunas em um vetor
df_combined = df.withColumn("features", array("feature1", "feature2", "feature3"))

df_combined.show(truncate=False)
