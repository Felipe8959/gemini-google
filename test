from pyspark.sql.functions import udf
from pyspark.sql.types import ArrayType, StringType

# Definindo uma UDF para tokenização simples
def tokenize_text(text):
    return text.split()

# Registrando a UDF
tokenize_udf = udf(tokenize_text, ArrayType(StringType()))

# Aplicando a UDF para criar a coluna 'tokens_cliente'
df_tokens_cliente = df.withColumn("tokens_cliente", tokenize_udf(df["texto_cliente"]))
df_tokens_cliente.show()
