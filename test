from pyspark.sql.functions import col, dense_rank
from pyspark.sql.window import Window

# Criar um DataFrame com categorias únicas e ordená-las por frequência
category_freq = df.groupBy("ANALISE_RESPOSTA").count().orderBy(col("count").desc())

# Adicionar índices às categorias usando dense_rank
category_freq = category_freq.withColumn("ANALISE_RESPOSTA_INDEX", dense_rank().over(Window.orderBy(col("count").desc())) - 1)

# Criar um dicionário de mapeamento
category_mapping = {row['ANALISE_RESPOSTA']: row['ANALISE_RESPOSTA_INDEX'] for row in category_freq.collect()}

# Aplicar o mapeamento no DataFrame original
from pyspark.sql.functions import udf
from pyspark.sql.types import IntegerType

# UDF para mapear categorias
def map_categories(category):
    return category_mapping.get(category, -1)  # Retorna -1 se a categoria não for encontrada

map_categories_udf = udf(map_categories, IntegerType())

# Criar a coluna de índice de resposta
df_indexed = df.withColumn("ANALISE_RESPOSTA_INDEX", map_categories_udf(col("ANALISE_RESPOSTA")))
df_indexed.show(truncate=False)
