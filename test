## Combinação de Vetorizadores
### TF-IDF com outras representações

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import FeatureUnion

# Combinação de diferentes vetorizadores
vectorizer_combo = FeatureUnion([
    ('tfidf_words', TfidfVectorizer(ngram_range=(1,2), max_features=3000)),
    ('tfidf_chars', TfidfVectorizer(analyzer='char', ngram_range=(2,4), max_features=2000)),
    ('count_vec', CountVectorizer(ngram_range=(1,1), max_features=1000, binary=True))
])


## Modelos Mais Sofisticados
### Ensemble
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.ensemble import VotingClassifier
from xgboost import XGBClassifier

# Ensemble de modelos
rf = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)
xgb = XGBClassifier(n_estimators=200, max_depth=6, learning_rate=0.1, random_state=42)
lr = LogisticRegression(**seus_melhores_params)

ensemble = VotingClassifier([
    ('lr', lr),
    ('rf', rf),
    ('xgb', xgb)
], voting='soft')


### Stacking
from sklearn.ensemble import StackingClassifier

stacking_model = StackingClassifier(
    estimators=[
        ('lr', LogisticRegression(**seus_params)),
        ('rf', RandomForestClassifier(n_estimators=100)),
        ('xgb', XGBClassifier(n_estimators=100))
    ],
    final_estimator=LogisticRegression(),
    cv=5
)

## Otimização de Threshold
from sklearn.metrics import precision_recall_curve

def optimize_threshold(y_true, y_proba):
    precision, recall, thresholds = precision_recall_curve(y_true, y_proba)
    f1_scores = 2 * (precision * recall) / (precision + recall)
    best_threshold = thresholds[np.argmax(f1_scores)]
    return best_threshold

# Após treinar o modelo
y_proba = model.predict_proba(X_test)[:, 1]
optimal_threshold = optimize_threshold(y_test, y_proba)
y_pred_optimized = (y_proba >= optimal_threshold).astype(int)

## Validação mais robusta
from sklearn.model_selection import StratifiedKFold, cross_validate

# Cross-validation mais robusta
cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)
scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']

cv_results = cross_validate(pipeline, X, y, cv=cv, scoring=scoring)

## Análise de erros
# Análise dos casos mal classificados
wrong_predictions = X_test[y_test != y_pred]
wrong_labels = y_test[y_test != y_pred]

# Examine exemplos específicos
false_positives = X_test[(y_test == 0) & (y_pred == 1)]
false_negatives = X_test[(y_test == 1) & (y_pred == 0)]

## EXEMPLO DE PIPELINE MELHORADO (EMBEDDINGS + XGBOOST)
from sentence_transformers import SentenceTransformer
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score

model = SentenceTransformer('all-MiniLM-L12-v2')
X = model.encode(df['texto'].tolist())
y = df['label'].values

X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)

clf = XGBClassifier(scale_pos_weight=len(y_train[y_train==0])/len(y_train[y_train==1]))
clf.fit(X_train, y_train)
preds = clf.predict(X_test)

print("F1 Score:", f1_score(y_test, preds))

## 3. ANÁLISE DOS ERROS (CONFUSÃO LOCAL)
### Extraia os falsos negativos e falsos positivos.

### Clusterize com UMAP + HDBSCAN para entender padrões nos erros.

### Pode descobrir que há padrões semânticos ou estruturais que passam despercebidos pelo TF-IDF.

## TROQUE TF-IDF POR EMBEDDINGS DENSOS
POR QUÊ: TF-IDF não entende semântica. Mesmo com n-grams, ele perde relações profundas.

AÇÃO: Testar com embeddings pré-treinados:

SentenceTransformer (paraphrase-MiniLM-L6-v2 ou all-MiniLM-L12-v2)

spaCy vectors (pt_core_news_lg, se estiver em português)

from sentence_transformers import SentenceTransformer
model = SentenceTransformer('paraphrase-MiniLM-L6-v2')
X_vectors = model.encode(texts)
