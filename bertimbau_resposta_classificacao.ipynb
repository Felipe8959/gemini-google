{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54c11530",
   "metadata": {},
   "source": [
    "# Classifica√ß√£o de Respostas de Analistas com BERTimbau\n",
    "Este notebook mostra, passo a passo, como treinar um classificador bin√°rio (0 = resposta **incompleta**, 1 = resposta **completa**) usando o modelo **BERTimbau** da Neuralmind e a biblioteca ü§ó *Transformers*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5febdef9",
   "metadata": {},
   "source": [
    "## 0.¬†Pr√©‚Äërequisitos\n",
    "Instalamos as principais bibliotecas necess√°rias para todo o fluxo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e15fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets evaluate torch scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6694937a",
   "metadata": {},
   "source": [
    "## 1.¬†Carregar e inspecionar o conjunto de dados\n",
    "Leitura do CSV com as colunas **`texto_manifestacao`**, **`texto_resposta`** e **`analise_resposta`**. Convertendo o r√≥tulo para inteiro e conferindo o balanceamento das classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b2fc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# üîÅ Altere o caminho do arquivo se necess√°rio\n",
    "df = pd.read_csv(\"manifestacoes.csv\")\n",
    "df[\"analise_resposta\"] = df[\"analise_resposta\"].astype(int)\n",
    "\n",
    "display(df['analise_resposta'].value_counts())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172f87d6",
   "metadata": {},
   "source": [
    "## 2.¬†Fundir manifesta√ß√£o + resposta (opcional)\n",
    "Em muitos casos apenas a **resposta** j√° basta, mas podemos concatenar a manifesta√ß√£o para dar contexto. A separa√ß√£o `[SEP]` ajuda o modelo a distinguir as duas partes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea91320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['texto_full'] = df['texto_manifestacao'].fillna('') + ' [SEP] ' + df['texto_resposta'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfae2c17",
   "metadata": {},
   "source": [
    "## 3.¬†Criar `Dataset` HuggingFace e dividir em treino/valida√ß√£o\n",
    "Usamos *train_test_split* estratificado para manter a propor√ß√£o de classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aded0d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    df, test_size=0.15, stratify=df['analise_resposta'], random_state=42\n",
    ")\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "val_ds   = Dataset.from_pandas(val_df.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4e30f7",
   "metadata": {},
   "source": [
    "## 4.¬†Tokenizar com o BERTimbau\n",
    "Carregamos o **tokenizer** e aplicamos truncamento e padding para tamanho fixo de sequ√™ncia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d01c45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = 'neuralmind/bert-base-portuguese-cased'\n",
    "tokenizer  = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(\n",
    "        batch['texto_full'],\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "train_ds = train_ds.map(tokenize, batched=True, remove_columns=train_ds.column_names)\n",
    "val_ds   = val_ds.map(tokenize, batched=True, remove_columns=val_ds.column_names)\n",
    "\n",
    "train_ds.set_format('torch')\n",
    "val_ds.set_format('torch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784ec9e2",
   "metadata": {},
   "source": [
    "## 5.¬†Definir o modelo de classifica√ß√£o\n",
    "`BertForSequenceClassification` adiciona uma camada linear ao topo do BERT. `num_labels=2` informa que o problema √© bin√°rio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b87e1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint,\n",
    "    num_labels=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d1d3e8",
   "metadata": {},
   "source": [
    "## 6.¬†Configurar treinamento\n",
    "Definimos hiperpar√¢metros no `TrainingArguments` e passamos tudo ao `Trainer`. M√©tricas usadas: *accuracy* e *F1‚Äëmacro*. Ajuste `per_device_train_batch_size` conforme sua GPU/CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50286d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import evaluate, numpy as np\n",
    "\n",
    "accuracy = evaluate.load('accuracy')\n",
    "f1       = evaluate.load('f1')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        'accuracy': accuracy.compute(predictions=preds, references=labels)['accuracy'],\n",
    "        'f1':       f1.compute(predictions=preds, references=labels, average='macro')['f1']\n",
    "    }\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir='bertimbau-resposta',\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1',\n",
    "    greater_is_better=True,\n",
    "    logging_steps=50,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555b1c2d",
   "metadata": {},
   "source": [
    "## 7.¬†Treinar\n",
    "> **Observa√ß√£o**: esta c√©lula pode levar minutos ou horas dependendo do tamanho do dataset e do hardware. Para testes r√°pidos, reduza `num_train_epochs` ou use amostra menor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b192fafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomente para treinar\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedbca52",
   "metadata": {},
   "source": [
    "## 8.¬†Avaliar e interpretar resultados\n",
    "Depois do treinamento, avaliamos o modelo no conjunto de valida√ß√£o e examinamos a matriz de confus√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784be6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = trainer.evaluate()\n",
    "# print(metrics)\n",
    "\n",
    "# from sklearn.metrics import confusion_matrix, classification_report\n",
    "# import torch\n",
    "# preds = trainer.predict(val_ds).predictions\n",
    "# y_pred = np.argmax(preds, axis=-1)\n",
    "# y_true = val_ds['labels']\n",
    "\n",
    "# print(confusion_matrix(y_true, y_pred))\n",
    "# print(classification_report(y_true, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a73521a",
   "metadata": {},
   "source": [
    "## 9.¬†Fazer previs√µes em novos casos\n",
    "Fun√ß√£o helper que devolve `pred` (0 ou 1) e as probabilidades para cada classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75cc2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prever(texto_manifestacao, texto_resposta):\n",
    "    seq = texto_manifestacao + ' [SEP] ' + texto_resposta\n",
    "    tokens = tokenizer(seq, return_tensors='pt', truncation=True, padding='max_length', max_length=256)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**tokens).logits\n",
    "    prob = torch.softmax(logits, dim=1).squeeze()\n",
    "    pred = torch.argmax(prob).item()\n",
    "    return pred, prob.tolist()\n",
    "\n",
    "# Exemplo de uso (modelo deve estar treinado!)\n",
    "# pred, prob = prever(\n",
    "#     'Cliente reclama de atraso na entrega.',\n",
    "#     'Entramos em contato com o cliente por telefone em 07/05 √†s 14h e confirmamos nova data de entrega para 10/05.'\n",
    "# )\n",
    "# print(f'Previs√£o: {pred}  Probabilidades: {prob}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2575b66c",
   "metadata": {},
   "source": [
    "## 10.¬†Salvar e recarregar o modelo\n",
    "```python\n",
    "trainer.save_model('bertimbau_resposta_final')\n",
    "```\n",
    "Depois, em outro script ou notebook, basta:\n",
    "```python\n",
    "model = AutoModelForSequenceClassification.from_pretrained('bertimbau_resposta_final')\n",
    "tokenizer = AutoTokenizer.from_pretrained('bertimbau_resposta_final')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909acc38",
   "metadata": {},
   "source": [
    "## Observa√ß√µes finais\n",
    "* Use GPU (`model.to('cuda')` ou `device_map='auto'`) para acelerar o treinamento.\n",
    "* Ajuste `max_length` se suas respostas forem muito longas.\n",
    "* Se a classe 1 ou 0 for rara, experimente reamostrar ou usar pesos de classe.\n",
    "* Ferramentas como **LIME** ou **SHAP** podem ajudar a explicar as previs√µes do modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
